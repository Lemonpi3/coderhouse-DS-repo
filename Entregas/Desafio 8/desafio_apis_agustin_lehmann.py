# -*- coding: utf-8 -*-
"""Desafio_APIS_Agustin_Lehmann.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_qN0MUiVfLDtJt2VuWVgHH8wNwemt3gB

Como en ninguno de mis datasets veo q me puedo aprobechar del uso de una api externa voy a extaer tweets relacionados a una empresa de internet local (Telecentro) lo cual seria el caso mas cercano de un uso de api a mi dataset de churn que proviene de una empresa de el mismo rubro (pero no decia en ningun lado el nombre de la empresa)
>
En este caso voy a empezar orientando la extracción a un sentiment analysis para medir la satisfacción de los usuarios por zonas y como hablan de la empresa.
>
Tambien se podria trackear a la competencia para ver que promociones e impacto en la comunidad tienen.
"""

!pip install tweepy

import pandas as pd

import tweepy

KEY = 'x8BfNYzKdXPlR3wAQW8ouS46P'
SECRET = 'Zn9GNVeTJ6KZ6S1Zm8ys28BEoJNeZzpTjeYxVFJWIVKQOcQdKi'

auth = tweepy.AppAuthHandler(KEY, SECRET)
api = tweepy.API(auth,wait_on_rate_limit=True)

"""Voy a ver que me da cada uno"""

#excluyo entidades pq molestaban mas que ayudaban
tweets = api.search(q='telecentro',lang='es',count=10,include_entities=False)

tweets[4]._json

"""Filtro el json ya que no quiero todo"""

#preparo las columnas que quiero que tenga el dataframe final
dict_df_final = {
    'tweet_id':[],
    'text':[],
    'fecha_creacion':[],
    'n_veces_retweeteado':[],
    'n_veces_favoriteado':[],
    'locacion_tweet':[],
    'in_reply_to_screen_name':[],
    'user':[],
    'user_id_creacion':[],
    'locacion_usuario':[],
    'n_seguidores_usuario':[],
    'n_seguidos_por_usuario':[],
    'fecha_usuario_creado':[],
    'n_favoritos_usuario':[],
    'n_tweets_usuario':[],
    }

"""¿Por qué elegí esas columnas?

* tweet_id/user_id_creacion/usuario : identificadores del tweet y de quien lo posteo

* text: lo q se va a analizar con el sentiment analisis
* fecha_creación: cuando ocurrió el tweet
* n_veces_retweeteado/favoriteado: el tamaño impacto en la comunidad, a cuantas personas llego (a mas retweets = a mas gente le llego)
* in_reply_to_screen_name: nombre de usuario al que le responde para filtrar los mensajes al servicio tecnico por tweeter q ofrece la empresa.
* locacion_tweet/usuario: para intentar saber en q zona esta ocurriendo el problema, la locación del tweet seria la zona principal y en caso de ser nula la locacion usuario puede servir como segunda opcion.
* n_seguidores_usuario , n_seguidos_por_usuario, n_tweets_usuario, n_favoritos_usuario , fecha_usuario_creado: pueden ser usados como metricas para distinguir si un usuario es un potencial bot o real.
"""

def parse_json(data):
  dict_df_final['tweet_id'].append(data['id'])
  dict_df_final['text'].append(data['text'])
  dict_df_final['fecha_creacion'].append(data['created_at'])
  dict_df_final['n_veces_retweeteado'].append(data['retweet_count'])
  dict_df_final['n_veces_favoriteado'].append(data['favorite_count'])
  dict_df_final['locacion_tweet'].append(data['place'])
  dict_df_final['in_reply_to_screen_name'].append(data['in_reply_to_screen_name'])
  dict_df_final['user_id_creacion'].append(data['user']['id'])
  dict_df_final['user'].append(data['user']['screen_name'])
  dict_df_final['locacion_usuario'].append(data['user']['location'])
  dict_df_final['n_seguidores_usuario'].append(data['user']['followers_count'])
  dict_df_final['n_seguidos_por_usuario'].append(data['user']['friends_count'])
  dict_df_final['fecha_usuario_creado'].append(data['user']['created_at'])
  dict_df_final['n_favoritos_usuario'].append(data['user']['favourites_count'])
  dict_df_final['n_tweets_usuario'].append(data['user']['statuses_count'])

#veo como se comporta a menor escala
for tweet in tweets:
  parse_json(tweet._json)

pd.DataFrame(dict_df_final)

#reseto el dict y hago el querry grande
dict_df_final = {
    'tweet_id':[],
    'text':[],
    'fecha_creacion':[],
    'n_veces_retweeteado':[],
    'n_veces_favoriteado':[],
    'locacion_tweet':[],
    'in_reply_to_screen_name':[],
    'user':[],
    'user_id_creacion':[],
    'locacion_usuario':[],
    'n_seguidores_usuario':[],
    'n_seguidos_por_usuario':[],
    'fecha_usuario_creado':[],
    'n_favoritos_usuario':[],
    'n_tweets_usuario':[],
    }
    
tweets = api.search(q='telecentro',lang='es',count=500,include_entities=False)

for tweet in tweets:
  parse_json(tweet._json)

df = pd.DataFrame(dict_df_final)

df

"""bueno, la api solo me deja los ultimos 100 tweets sin pagar 🙂"""

